{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "street view house number.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpDHzGgVWIKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19f642ab-ac0f-4c96-9394-5710e91aee38"
      },
      "source": [
        "#파일 불러오기\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "from scipy import io\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwMdelHXW4v7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#파일불러오기 2\n",
        "test_32x32 = io.loadmat('/gdrive/My Drive/deeplearning/test_32x32.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hQoqPcqXXQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04567388-6ea3-421c-d553-b4d57c9ba71d"
      },
      "source": [
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5av9JdyOXXMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e9402132-e9ab-4c0f-bebd-e0bbc1652dc5"
      },
      "source": [
        "#x,y값 받아오기\n",
        "x=np.array(test_32x32.get('X'))\n",
        "y=np.array(test_32x32.get('y'))\n",
        "x.shape,y.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 32, 3, 26032), (26032, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KBoOdRoaGt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x값 모양 변경\n",
        "x=np.swapaxes(x,2,3)\n",
        "x=np.swapaxes(x,1,2)\n",
        "x=np.swapaxes(x,0,1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLeDELt1aQco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y값 변경\n",
        "y=np.reshape(y,(-1,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6G9r3HlaGfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05440879-f20d-4710-c5f0-fa558d858b1d"
      },
      "source": [
        "#확인\n",
        "x.shape,y.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((26032, 32, 32, 3), (26032,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vy9sZaRsd47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e183d146-8a44-4ecb-8c38-f5c5cb07e105"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[ 38 103  60]\n",
            "   [ 39 104  61]\n",
            "   [ 39 104  62]\n",
            "   ...\n",
            "   [ 41 102  61]\n",
            "   [ 42 103  62]\n",
            "   [ 39  97  57]]\n",
            "\n",
            "  [[ 39 104  61]\n",
            "   [ 39 104  61]\n",
            "   [ 39 104  62]\n",
            "   ...\n",
            "   [ 41 102  61]\n",
            "   [ 43 101  63]\n",
            "   [ 39  97  57]]\n",
            "\n",
            "  [[ 38 105  62]\n",
            "   [ 37 104  61]\n",
            "   [ 39 106  63]\n",
            "   ...\n",
            "   [ 43 101  63]\n",
            "   [ 43 100  64]\n",
            "   [ 39  97  59]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 52 119  78]\n",
            "   [ 53 120  79]\n",
            "   [ 51 118  77]\n",
            "   ...\n",
            "   [ 44 118  69]\n",
            "   [ 44 117  71]\n",
            "   [ 41 114  69]]\n",
            "\n",
            "  [[ 50 117  76]\n",
            "   [ 51 118  77]\n",
            "   [ 49 116  75]\n",
            "   ...\n",
            "   [ 44 117  71]\n",
            "   [ 45 116  72]\n",
            "   [ 42 113  69]]\n",
            "\n",
            "  [[ 48 115  74]\n",
            "   [ 48 115  74]\n",
            "   [ 46 113  72]\n",
            "   ...\n",
            "   [ 43 116  71]\n",
            "   [ 44 115  71]\n",
            "   [ 42 113  71]]]\n",
            "\n",
            "\n",
            " [[[129 142 153]\n",
            "   [127 143 152]\n",
            "   [125 143 151]\n",
            "   ...\n",
            "   [121 133 153]\n",
            "   [123 134 156]\n",
            "   [123 135 157]]\n",
            "\n",
            "  [[134 150 160]\n",
            "   [133 149 158]\n",
            "   [132 149 157]\n",
            "   ...\n",
            "   [127 138 157]\n",
            "   [126 137 157]\n",
            "   [125 137 158]]\n",
            "\n",
            "  [[141 158 168]\n",
            "   [140 157 166]\n",
            "   [140 157 165]\n",
            "   ...\n",
            "   [135 147 163]\n",
            "   [132 143 161]\n",
            "   [130 141 160]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[147 161 174]\n",
            "   [142 156 169]\n",
            "   [136 151 163]\n",
            "   ...\n",
            "   [ 93  97 126]\n",
            "   [ 96 100 128]\n",
            "   [104 109 136]]\n",
            "\n",
            "  [[138 152 165]\n",
            "   [130 144 157]\n",
            "   [121 136 148]\n",
            "   ...\n",
            "   [ 93  99 128]\n",
            "   [101 107 134]\n",
            "   [112 118 144]]\n",
            "\n",
            "  [[131 145 158]\n",
            "   [122 136 149]\n",
            "   [111 126 139]\n",
            "   ...\n",
            "   [101 108 135]\n",
            "   [111 118 144]\n",
            "   [123 130 156]]]\n",
            "\n",
            "\n",
            " [[[150 160 169]\n",
            "   [150 163 170]\n",
            "   [152 168 172]\n",
            "   ...\n",
            "   [153 172 180]\n",
            "   [150 171 181]\n",
            "   [147 169 180]]\n",
            "\n",
            "  [[150 160 169]\n",
            "   [151 163 169]\n",
            "   [153 168 171]\n",
            "   ...\n",
            "   [156 174 180]\n",
            "   [153 171 180]\n",
            "   [150 169 179]]\n",
            "\n",
            "  [[144 154 163]\n",
            "   [146 157 163]\n",
            "   [148 162 165]\n",
            "   ...\n",
            "   [157 172 177]\n",
            "   [153 168 175]\n",
            "   [150 165 173]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[135 150 167]\n",
            "   [134 149 166]\n",
            "   [132 147 165]\n",
            "   ...\n",
            "   [124 140 157]\n",
            "   [122 139 157]\n",
            "   [121 138 158]]\n",
            "\n",
            "  [[147 165 179]\n",
            "   [147 164 179]\n",
            "   [147 164 179]\n",
            "   ...\n",
            "   [139 155 170]\n",
            "   [139 155 170]\n",
            "   [138 155 171]]\n",
            "\n",
            "  [[159 177 189]\n",
            "   [159 177 190]\n",
            "   [159 177 191]\n",
            "   ...\n",
            "   [152 168 181]\n",
            "   [152 168 182]\n",
            "   [152 168 183]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[115 132 142]\n",
            "   [116 133 143]\n",
            "   [117 134 144]\n",
            "   ...\n",
            "   [114 136 141]\n",
            "   [114 136 142]\n",
            "   [115 136 143]]\n",
            "\n",
            "  [[122 139 148]\n",
            "   [123 140 149]\n",
            "   [124 141 150]\n",
            "   ...\n",
            "   [118 139 143]\n",
            "   [118 139 145]\n",
            "   [119 139 146]]\n",
            "\n",
            "  [[131 148 155]\n",
            "   [132 149 156]\n",
            "   [133 149 157]\n",
            "   ...\n",
            "   [125 143 147]\n",
            "   [125 143 149]\n",
            "   [126 144 150]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 94  97 114]\n",
            "   [ 93  96 113]\n",
            "   [ 92  95 112]\n",
            "   ...\n",
            "   [140 153 162]\n",
            "   [142 155 164]\n",
            "   [144 157 165]]\n",
            "\n",
            "  [[117 122 137]\n",
            "   [117 122 137]\n",
            "   [118 123 137]\n",
            "   ...\n",
            "   [141 154 163]\n",
            "   [143 156 164]\n",
            "   [144 157 165]]\n",
            "\n",
            "  [[132 138 152]\n",
            "   [133 140 152]\n",
            "   [135 142 153]\n",
            "   ...\n",
            "   [142 155 164]\n",
            "   [143 156 165]\n",
            "   [144 157 165]]]\n",
            "\n",
            "\n",
            " [[[ 96  65  47]\n",
            "   [ 97  65  49]\n",
            "   [ 97  65  50]\n",
            "   ...\n",
            "   [ 86  61  54]\n",
            "   [ 87  62  55]\n",
            "   [ 88  63  56]]\n",
            "\n",
            "  [[ 96  65  48]\n",
            "   [ 97  65  50]\n",
            "   [ 97  65  51]\n",
            "   ...\n",
            "   [ 85  62  53]\n",
            "   [ 87  63  54]\n",
            "   [ 88  64  55]]\n",
            "\n",
            "  [[ 96  64  49]\n",
            "   [ 96  64  50]\n",
            "   [ 96  64  51]\n",
            "   ...\n",
            "   [ 87  66  54]\n",
            "   [ 90  68  57]\n",
            "   [ 91  69  58]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 99  68  48]\n",
            "   [ 99  70  50]\n",
            "   [100  73  53]\n",
            "   ...\n",
            "   [138 121 105]\n",
            "   [127 109  93]\n",
            "   [117  98  83]]\n",
            "\n",
            "  [[ 98  67  46]\n",
            "   [ 99  70  48]\n",
            "   [100  73  51]\n",
            "   ...\n",
            "   [126 108  92]\n",
            "   [118  99  83]\n",
            "   [110  91  75]]\n",
            "\n",
            "  [[ 97  66  45]\n",
            "   [ 99  69  48]\n",
            "   [100  72  51]\n",
            "   ...\n",
            "   [118  99  82]\n",
            "   [111  92  74]\n",
            "   [104  85  68]]]\n",
            "\n",
            "\n",
            " [[[101  75  60]\n",
            "   [100  73  60]\n",
            "   [ 99  71  59]\n",
            "   ...\n",
            "   [ 95  63  52]\n",
            "   [ 95  63  52]\n",
            "   [ 96  64  51]]\n",
            "\n",
            "  [[109  84  69]\n",
            "   [107  80  67]\n",
            "   [104  76  64]\n",
            "   ...\n",
            "   [ 95  62  53]\n",
            "   [ 93  61  50]\n",
            "   [ 93  61  49]]\n",
            "\n",
            "  [[117  95  78]\n",
            "   [114  90  75]\n",
            "   [108  83  70]\n",
            "   ...\n",
            "   [ 95  62  53]\n",
            "   [ 92  60  50]\n",
            "   [ 91  59  48]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[116  96  85]\n",
            "   [116  96  87]\n",
            "   [115  95  87]\n",
            "   ...\n",
            "   [101  70  50]\n",
            "   [101  70  50]\n",
            "   [101  70  50]]\n",
            "\n",
            "  [[104  83  71]\n",
            "   [105  84  73]\n",
            "   [105  84  74]\n",
            "   ...\n",
            "   [101  70  49]\n",
            "   [102  71  50]\n",
            "   [102  71  50]]\n",
            "\n",
            "  [[ 95  73  62]\n",
            "   [ 96  74  63]\n",
            "   [ 97  75  64]\n",
            "   ...\n",
            "   [101  70  49]\n",
            "   [102  71  50]\n",
            "   [102  71  50]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jUxtou2aY04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46633016-ff20-4249-bacb-9f71e0aa994d"
      },
      "source": [
        "#y의 라벨 변경(10->0)\n",
        "y=np.where(y==10,0,y)\n",
        "y"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 2, 1, ..., 7, 6, 7], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3RG-HXEmr-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63538df6-357e-44b2-9705-f58c83871bf6"
      },
      "source": [
        "x=x/255\n",
        "\n",
        "x"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.14901961, 0.40392157, 0.23529412],\n",
              "         [0.15294118, 0.40784314, 0.23921569],\n",
              "         [0.15294118, 0.40784314, 0.24313725],\n",
              "         ...,\n",
              "         [0.16078431, 0.4       , 0.23921569],\n",
              "         [0.16470588, 0.40392157, 0.24313725],\n",
              "         [0.15294118, 0.38039216, 0.22352941]],\n",
              "\n",
              "        [[0.15294118, 0.40784314, 0.23921569],\n",
              "         [0.15294118, 0.40784314, 0.23921569],\n",
              "         [0.15294118, 0.40784314, 0.24313725],\n",
              "         ...,\n",
              "         [0.16078431, 0.4       , 0.23921569],\n",
              "         [0.16862745, 0.39607843, 0.24705882],\n",
              "         [0.15294118, 0.38039216, 0.22352941]],\n",
              "\n",
              "        [[0.14901961, 0.41176471, 0.24313725],\n",
              "         [0.14509804, 0.40784314, 0.23921569],\n",
              "         [0.15294118, 0.41568627, 0.24705882],\n",
              "         ...,\n",
              "         [0.16862745, 0.39607843, 0.24705882],\n",
              "         [0.16862745, 0.39215686, 0.25098039],\n",
              "         [0.15294118, 0.38039216, 0.23137255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.20392157, 0.46666667, 0.30588235],\n",
              "         [0.20784314, 0.47058824, 0.30980392],\n",
              "         [0.2       , 0.4627451 , 0.30196078],\n",
              "         ...,\n",
              "         [0.17254902, 0.4627451 , 0.27058824],\n",
              "         [0.17254902, 0.45882353, 0.27843137],\n",
              "         [0.16078431, 0.44705882, 0.27058824]],\n",
              "\n",
              "        [[0.19607843, 0.45882353, 0.29803922],\n",
              "         [0.2       , 0.4627451 , 0.30196078],\n",
              "         [0.19215686, 0.45490196, 0.29411765],\n",
              "         ...,\n",
              "         [0.17254902, 0.45882353, 0.27843137],\n",
              "         [0.17647059, 0.45490196, 0.28235294],\n",
              "         [0.16470588, 0.44313725, 0.27058824]],\n",
              "\n",
              "        [[0.18823529, 0.45098039, 0.29019608],\n",
              "         [0.18823529, 0.45098039, 0.29019608],\n",
              "         [0.18039216, 0.44313725, 0.28235294],\n",
              "         ...,\n",
              "         [0.16862745, 0.45490196, 0.27843137],\n",
              "         [0.17254902, 0.45098039, 0.27843137],\n",
              "         [0.16470588, 0.44313725, 0.27843137]]],\n",
              "\n",
              "\n",
              "       [[[0.50588235, 0.55686275, 0.6       ],\n",
              "         [0.49803922, 0.56078431, 0.59607843],\n",
              "         [0.49019608, 0.56078431, 0.59215686],\n",
              "         ...,\n",
              "         [0.4745098 , 0.52156863, 0.6       ],\n",
              "         [0.48235294, 0.5254902 , 0.61176471],\n",
              "         [0.48235294, 0.52941176, 0.61568627]],\n",
              "\n",
              "        [[0.5254902 , 0.58823529, 0.62745098],\n",
              "         [0.52156863, 0.58431373, 0.61960784],\n",
              "         [0.51764706, 0.58431373, 0.61568627],\n",
              "         ...,\n",
              "         [0.49803922, 0.54117647, 0.61568627],\n",
              "         [0.49411765, 0.5372549 , 0.61568627],\n",
              "         [0.49019608, 0.5372549 , 0.61960784]],\n",
              "\n",
              "        [[0.55294118, 0.61960784, 0.65882353],\n",
              "         [0.54901961, 0.61568627, 0.65098039],\n",
              "         [0.54901961, 0.61568627, 0.64705882],\n",
              "         ...,\n",
              "         [0.52941176, 0.57647059, 0.63921569],\n",
              "         [0.51764706, 0.56078431, 0.63137255],\n",
              "         [0.50980392, 0.55294118, 0.62745098]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.57647059, 0.63137255, 0.68235294],\n",
              "         [0.55686275, 0.61176471, 0.6627451 ],\n",
              "         [0.53333333, 0.59215686, 0.63921569],\n",
              "         ...,\n",
              "         [0.36470588, 0.38039216, 0.49411765],\n",
              "         [0.37647059, 0.39215686, 0.50196078],\n",
              "         [0.40784314, 0.42745098, 0.53333333]],\n",
              "\n",
              "        [[0.54117647, 0.59607843, 0.64705882],\n",
              "         [0.50980392, 0.56470588, 0.61568627],\n",
              "         [0.4745098 , 0.53333333, 0.58039216],\n",
              "         ...,\n",
              "         [0.36470588, 0.38823529, 0.50196078],\n",
              "         [0.39607843, 0.41960784, 0.5254902 ],\n",
              "         [0.43921569, 0.4627451 , 0.56470588]],\n",
              "\n",
              "        [[0.51372549, 0.56862745, 0.61960784],\n",
              "         [0.47843137, 0.53333333, 0.58431373],\n",
              "         [0.43529412, 0.49411765, 0.54509804],\n",
              "         ...,\n",
              "         [0.39607843, 0.42352941, 0.52941176],\n",
              "         [0.43529412, 0.4627451 , 0.56470588],\n",
              "         [0.48235294, 0.50980392, 0.61176471]]],\n",
              "\n",
              "\n",
              "       [[[0.58823529, 0.62745098, 0.6627451 ],\n",
              "         [0.58823529, 0.63921569, 0.66666667],\n",
              "         [0.59607843, 0.65882353, 0.6745098 ],\n",
              "         ...,\n",
              "         [0.6       , 0.6745098 , 0.70588235],\n",
              "         [0.58823529, 0.67058824, 0.70980392],\n",
              "         [0.57647059, 0.6627451 , 0.70588235]],\n",
              "\n",
              "        [[0.58823529, 0.62745098, 0.6627451 ],\n",
              "         [0.59215686, 0.63921569, 0.6627451 ],\n",
              "         [0.6       , 0.65882353, 0.67058824],\n",
              "         ...,\n",
              "         [0.61176471, 0.68235294, 0.70588235],\n",
              "         [0.6       , 0.67058824, 0.70588235],\n",
              "         [0.58823529, 0.6627451 , 0.70196078]],\n",
              "\n",
              "        [[0.56470588, 0.60392157, 0.63921569],\n",
              "         [0.57254902, 0.61568627, 0.63921569],\n",
              "         [0.58039216, 0.63529412, 0.64705882],\n",
              "         ...,\n",
              "         [0.61568627, 0.6745098 , 0.69411765],\n",
              "         [0.6       , 0.65882353, 0.68627451],\n",
              "         [0.58823529, 0.64705882, 0.67843137]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.52941176, 0.58823529, 0.65490196],\n",
              "         [0.5254902 , 0.58431373, 0.65098039],\n",
              "         [0.51764706, 0.57647059, 0.64705882],\n",
              "         ...,\n",
              "         [0.48627451, 0.54901961, 0.61568627],\n",
              "         [0.47843137, 0.54509804, 0.61568627],\n",
              "         [0.4745098 , 0.54117647, 0.61960784]],\n",
              "\n",
              "        [[0.57647059, 0.64705882, 0.70196078],\n",
              "         [0.57647059, 0.64313725, 0.70196078],\n",
              "         [0.57647059, 0.64313725, 0.70196078],\n",
              "         ...,\n",
              "         [0.54509804, 0.60784314, 0.66666667],\n",
              "         [0.54509804, 0.60784314, 0.66666667],\n",
              "         [0.54117647, 0.60784314, 0.67058824]],\n",
              "\n",
              "        [[0.62352941, 0.69411765, 0.74117647],\n",
              "         [0.62352941, 0.69411765, 0.74509804],\n",
              "         [0.62352941, 0.69411765, 0.74901961],\n",
              "         ...,\n",
              "         [0.59607843, 0.65882353, 0.70980392],\n",
              "         [0.59607843, 0.65882353, 0.71372549],\n",
              "         [0.59607843, 0.65882353, 0.71764706]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.45098039, 0.51764706, 0.55686275],\n",
              "         [0.45490196, 0.52156863, 0.56078431],\n",
              "         [0.45882353, 0.5254902 , 0.56470588],\n",
              "         ...,\n",
              "         [0.44705882, 0.53333333, 0.55294118],\n",
              "         [0.44705882, 0.53333333, 0.55686275],\n",
              "         [0.45098039, 0.53333333, 0.56078431]],\n",
              "\n",
              "        [[0.47843137, 0.54509804, 0.58039216],\n",
              "         [0.48235294, 0.54901961, 0.58431373],\n",
              "         [0.48627451, 0.55294118, 0.58823529],\n",
              "         ...,\n",
              "         [0.4627451 , 0.54509804, 0.56078431],\n",
              "         [0.4627451 , 0.54509804, 0.56862745],\n",
              "         [0.46666667, 0.54509804, 0.57254902]],\n",
              "\n",
              "        [[0.51372549, 0.58039216, 0.60784314],\n",
              "         [0.51764706, 0.58431373, 0.61176471],\n",
              "         [0.52156863, 0.58431373, 0.61568627],\n",
              "         ...,\n",
              "         [0.49019608, 0.56078431, 0.57647059],\n",
              "         [0.49019608, 0.56078431, 0.58431373],\n",
              "         [0.49411765, 0.56470588, 0.58823529]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.36862745, 0.38039216, 0.44705882],\n",
              "         [0.36470588, 0.37647059, 0.44313725],\n",
              "         [0.36078431, 0.37254902, 0.43921569],\n",
              "         ...,\n",
              "         [0.54901961, 0.6       , 0.63529412],\n",
              "         [0.55686275, 0.60784314, 0.64313725],\n",
              "         [0.56470588, 0.61568627, 0.64705882]],\n",
              "\n",
              "        [[0.45882353, 0.47843137, 0.5372549 ],\n",
              "         [0.45882353, 0.47843137, 0.5372549 ],\n",
              "         [0.4627451 , 0.48235294, 0.5372549 ],\n",
              "         ...,\n",
              "         [0.55294118, 0.60392157, 0.63921569],\n",
              "         [0.56078431, 0.61176471, 0.64313725],\n",
              "         [0.56470588, 0.61568627, 0.64705882]],\n",
              "\n",
              "        [[0.51764706, 0.54117647, 0.59607843],\n",
              "         [0.52156863, 0.54901961, 0.59607843],\n",
              "         [0.52941176, 0.55686275, 0.6       ],\n",
              "         ...,\n",
              "         [0.55686275, 0.60784314, 0.64313725],\n",
              "         [0.56078431, 0.61176471, 0.64705882],\n",
              "         [0.56470588, 0.61568627, 0.64705882]]],\n",
              "\n",
              "\n",
              "       [[[0.37647059, 0.25490196, 0.18431373],\n",
              "         [0.38039216, 0.25490196, 0.19215686],\n",
              "         [0.38039216, 0.25490196, 0.19607843],\n",
              "         ...,\n",
              "         [0.3372549 , 0.23921569, 0.21176471],\n",
              "         [0.34117647, 0.24313725, 0.21568627],\n",
              "         [0.34509804, 0.24705882, 0.21960784]],\n",
              "\n",
              "        [[0.37647059, 0.25490196, 0.18823529],\n",
              "         [0.38039216, 0.25490196, 0.19607843],\n",
              "         [0.38039216, 0.25490196, 0.2       ],\n",
              "         ...,\n",
              "         [0.33333333, 0.24313725, 0.20784314],\n",
              "         [0.34117647, 0.24705882, 0.21176471],\n",
              "         [0.34509804, 0.25098039, 0.21568627]],\n",
              "\n",
              "        [[0.37647059, 0.25098039, 0.19215686],\n",
              "         [0.37647059, 0.25098039, 0.19607843],\n",
              "         [0.37647059, 0.25098039, 0.2       ],\n",
              "         ...,\n",
              "         [0.34117647, 0.25882353, 0.21176471],\n",
              "         [0.35294118, 0.26666667, 0.22352941],\n",
              "         [0.35686275, 0.27058824, 0.22745098]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.38823529, 0.26666667, 0.18823529],\n",
              "         [0.38823529, 0.2745098 , 0.19607843],\n",
              "         [0.39215686, 0.28627451, 0.20784314],\n",
              "         ...,\n",
              "         [0.54117647, 0.4745098 , 0.41176471],\n",
              "         [0.49803922, 0.42745098, 0.36470588],\n",
              "         [0.45882353, 0.38431373, 0.3254902 ]],\n",
              "\n",
              "        [[0.38431373, 0.2627451 , 0.18039216],\n",
              "         [0.38823529, 0.2745098 , 0.18823529],\n",
              "         [0.39215686, 0.28627451, 0.2       ],\n",
              "         ...,\n",
              "         [0.49411765, 0.42352941, 0.36078431],\n",
              "         [0.4627451 , 0.38823529, 0.3254902 ],\n",
              "         [0.43137255, 0.35686275, 0.29411765]],\n",
              "\n",
              "        [[0.38039216, 0.25882353, 0.17647059],\n",
              "         [0.38823529, 0.27058824, 0.18823529],\n",
              "         [0.39215686, 0.28235294, 0.2       ],\n",
              "         ...,\n",
              "         [0.4627451 , 0.38823529, 0.32156863],\n",
              "         [0.43529412, 0.36078431, 0.29019608],\n",
              "         [0.40784314, 0.33333333, 0.26666667]]],\n",
              "\n",
              "\n",
              "       [[[0.39607843, 0.29411765, 0.23529412],\n",
              "         [0.39215686, 0.28627451, 0.23529412],\n",
              "         [0.38823529, 0.27843137, 0.23137255],\n",
              "         ...,\n",
              "         [0.37254902, 0.24705882, 0.20392157],\n",
              "         [0.37254902, 0.24705882, 0.20392157],\n",
              "         [0.37647059, 0.25098039, 0.2       ]],\n",
              "\n",
              "        [[0.42745098, 0.32941176, 0.27058824],\n",
              "         [0.41960784, 0.31372549, 0.2627451 ],\n",
              "         [0.40784314, 0.29803922, 0.25098039],\n",
              "         ...,\n",
              "         [0.37254902, 0.24313725, 0.20784314],\n",
              "         [0.36470588, 0.23921569, 0.19607843],\n",
              "         [0.36470588, 0.23921569, 0.19215686]],\n",
              "\n",
              "        [[0.45882353, 0.37254902, 0.30588235],\n",
              "         [0.44705882, 0.35294118, 0.29411765],\n",
              "         [0.42352941, 0.3254902 , 0.2745098 ],\n",
              "         ...,\n",
              "         [0.37254902, 0.24313725, 0.20784314],\n",
              "         [0.36078431, 0.23529412, 0.19607843],\n",
              "         [0.35686275, 0.23137255, 0.18823529]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.45490196, 0.37647059, 0.33333333],\n",
              "         [0.45490196, 0.37647059, 0.34117647],\n",
              "         [0.45098039, 0.37254902, 0.34117647],\n",
              "         ...,\n",
              "         [0.39607843, 0.2745098 , 0.19607843],\n",
              "         [0.39607843, 0.2745098 , 0.19607843],\n",
              "         [0.39607843, 0.2745098 , 0.19607843]],\n",
              "\n",
              "        [[0.40784314, 0.3254902 , 0.27843137],\n",
              "         [0.41176471, 0.32941176, 0.28627451],\n",
              "         [0.41176471, 0.32941176, 0.29019608],\n",
              "         ...,\n",
              "         [0.39607843, 0.2745098 , 0.19215686],\n",
              "         [0.4       , 0.27843137, 0.19607843],\n",
              "         [0.4       , 0.27843137, 0.19607843]],\n",
              "\n",
              "        [[0.37254902, 0.28627451, 0.24313725],\n",
              "         [0.37647059, 0.29019608, 0.24705882],\n",
              "         [0.38039216, 0.29411765, 0.25098039],\n",
              "         ...,\n",
              "         [0.39607843, 0.2745098 , 0.19215686],\n",
              "         [0.4       , 0.27843137, 0.19607843],\n",
              "         [0.4       , 0.27843137, 0.19607843]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8UTgd2EXXJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40be5221-b382-4d1d-e8bf-2e0e1140955b"
      },
      "source": [
        "m = len(y)//2\n",
        "x_train = x[:m]\n",
        "y_train = y[:m]\n",
        "x_test = x[m:m*2]\n",
        "y_test = y[m:m*2]\n",
        "\n",
        "x_train.shape , y_train.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13016, 32, 32, 3), (13016,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFgWcSc9XXHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#전문가 모델\n",
        "class MyModel(keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()#상속한 클래스의 생성자 호출 \n",
        "    self.opt = tf.optimizers.RMSprop(learning_rate=0.01)#Stochatic Gradient Descent 확률적 경사 하강\n",
        "    self.conv0 = keras.layers.Conv2D(32, [3,3], padding='same', activation=keras.activations.relu)\n",
        "    self.conv1 = keras.layers.Conv2D(16, [3,3], padding='same', activation=keras.activations.relu)\n",
        "    self.conv2 = keras.layers.Conv2D(8, [3,3], padding='same', activation=keras.activations.relu)\n",
        "    self.conv3 = keras.layers.Conv2D(4, [3,3], padding='same', activation=keras.activations.relu)\n",
        "    self.pool0 = keras.layers.MaxPool2D([2,2], padding='same')\n",
        "    self.pool1 = keras.layers.MaxPool2D([2,2], padding='same')\n",
        "    # self.pool2 = keras.layers.MaxPool2D([2,2], padding='same')\n",
        "    # self.pool3 = keras.layers.MaxPool2D([2,2], padding='same')\n",
        "    self.flatten = keras.layers.Flatten()\n",
        "    self.dense1 = keras.layers.Dense(32, activation='sigmoid')\n",
        "    self.dense0 = keras.layers.Dense(units=10, activation=keras.activations.softmax)\n",
        "  \n",
        "  def call(self, x):\n",
        "    #x (1797, 64)\n",
        "    x_4d = tf.reshape(x, [-1,32,32,3]) \n",
        "    x_4d = tf.cast(x_4d, tf.float32)\n",
        "    net = self.conv0(x_4d)\n",
        "    net = self.pool0(net)\n",
        "    net = self.conv1(net)\n",
        "    net = self.pool1(net)\n",
        "    net = self.conv2(net)\n",
        "    # net = self.pool2(net)\n",
        "    net = self.conv3(net)\n",
        "    # net = self.pool3(net)\n",
        "    net = self.flatten(net)  \n",
        "    net = self.dense1(net)  \n",
        "    h = self.dense0(net)\n",
        "    return h\n",
        "\n",
        "  def get_loss(self, y, h):\n",
        "    #학습할때 nan이 발생하는 경우 값을 clip(자르다) (최소값, 최대값) \n",
        "    h = tf.clip_by_value(h, 1e-8, 1 - 1e-8) # h 가 0이나 1이 되지 않도록 하는 안전장치 \n",
        "    cross_entropy = - (y * tf.math.log(h) + (1 - y) * tf.math.log(1 - h)) \n",
        "    loss = tf.reduce_mean(cross_entropy)\n",
        "    return loss\n",
        "\n",
        "  def get_accuracy(self, y, h):    \n",
        "    predict = tf.argmax(h, -1)\n",
        "    \n",
        "    self.acc = tf.reduce_mean(tf.cast(tf.equal(y, predict), tf.float32)) # True > 1, False > 0 로 cast\n",
        "\n",
        "  def fit(self, x, y, epoch=1):\n",
        "    # x : (m, 4), y: (m)    \n",
        "    y_hot = tf.one_hot(y, depth=10, axis=-1)#(m, 3)  \n",
        "    for i in range(epoch):\n",
        "        # iteration=np.ceil(len(y))\n",
        "        # for j in range(iteration):\n",
        "        #   start = j*batch_m\n",
        "        #   end= (j+1)*betch_m\n",
        "        #   x_batch=x[start:end]\n",
        "        #   y_batch=y[start:end]\n",
        "      with tf.GradientTape() as tape: #경사 기록 장치\n",
        "        h = self.call(x)\n",
        "        loss = self.get_loss(y_hot, h)        \n",
        "      grads = tape.gradient(loss, self.trainable_variables) #경사 계산\n",
        "      self.opt.apply_gradients(zip(grads, self.trainable_variables)) # 가중치에서 경사를 빼기\n",
        "      self.get_accuracy(y, h)\n",
        "      \n",
        "      if i%10==0:\n",
        "        print('%d/%d loss:%.3f acc:%.3f'%(i, epoch, loss, self.acc))\n",
        "model = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4L0Zubhet_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# epoch=100\n",
        "# batch_m=1000\n",
        "# for i in range(epoch):\n",
        "#   iteration=np.ceil(len(y)/batch_m)\n",
        "#   for j in range(iteration):\n",
        "#     start = j*batch_m\n",
        "#     end= (j+1)*batch_m\n",
        "#     x_batch=x[start:end]\n",
        "#     y_batch=y[start:end]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr4ZhEkGXXEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a27a5614-9f43-44ac-fb39-4bc65b0e4df1"
      },
      "source": [
        "model.fit(x_train, y_train, 800)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0/800 loss:0.367 acc:0.077\n",
            "10/800 loss:0.316 acc:0.195\n",
            "20/800 loss:0.317 acc:0.161\n",
            "30/800 loss:0.316 acc:0.163\n",
            "40/800 loss:0.306 acc:0.262\n",
            "50/800 loss:0.289 acc:0.318\n",
            "60/800 loss:0.266 acc:0.379\n",
            "70/800 loss:0.258 acc:0.434\n",
            "80/800 loss:0.233 acc:0.497\n",
            "90/800 loss:0.217 acc:0.530\n",
            "100/800 loss:0.191 acc:0.612\n",
            "110/800 loss:0.187 acc:0.618\n",
            "120/800 loss:0.180 acc:0.639\n",
            "130/800 loss:0.177 acc:0.642\n",
            "140/800 loss:0.154 acc:0.698\n",
            "150/800 loss:0.145 acc:0.718\n",
            "160/800 loss:0.149 acc:0.703\n",
            "170/800 loss:0.146 acc:0.708\n",
            "180/800 loss:0.136 acc:0.733\n",
            "190/800 loss:0.130 acc:0.745\n",
            "200/800 loss:0.146 acc:0.700\n",
            "210/800 loss:0.116 acc:0.777\n",
            "220/800 loss:0.125 acc:0.753\n",
            "230/800 loss:0.125 acc:0.754\n",
            "240/800 loss:0.108 acc:0.790\n",
            "250/800 loss:0.106 acc:0.796\n",
            "260/800 loss:0.125 acc:0.749\n",
            "270/800 loss:0.102 acc:0.806\n",
            "280/800 loss:0.098 acc:0.813\n",
            "290/800 loss:0.096 acc:0.815\n",
            "300/800 loss:0.098 acc:0.811\n",
            "310/800 loss:0.102 acc:0.802\n",
            "320/800 loss:0.094 acc:0.821\n",
            "330/800 loss:0.085 acc:0.844\n",
            "340/800 loss:0.085 acc:0.840\n",
            "350/800 loss:0.099 acc:0.809\n",
            "360/800 loss:0.082 acc:0.845\n",
            "370/800 loss:0.101 acc:0.805\n",
            "380/800 loss:0.083 acc:0.844\n",
            "390/800 loss:0.078 acc:0.854\n",
            "400/800 loss:0.073 acc:0.866\n",
            "410/800 loss:0.076 acc:0.857\n",
            "420/800 loss:0.072 acc:0.868\n",
            "430/800 loss:0.072 acc:0.869\n",
            "440/800 loss:0.100 acc:0.803\n",
            "450/800 loss:0.072 acc:0.868\n",
            "460/800 loss:0.072 acc:0.864\n",
            "470/800 loss:0.071 acc:0.867\n",
            "480/800 loss:0.074 acc:0.861\n",
            "490/800 loss:0.077 acc:0.851\n",
            "500/800 loss:0.070 acc:0.868\n",
            "510/800 loss:0.069 acc:0.870\n",
            "520/800 loss:0.065 acc:0.880\n",
            "530/800 loss:0.064 acc:0.883\n",
            "540/800 loss:0.064 acc:0.881\n",
            "550/800 loss:0.058 acc:0.896\n",
            "560/800 loss:0.062 acc:0.888\n",
            "570/800 loss:0.059 acc:0.891\n",
            "580/800 loss:0.059 acc:0.896\n",
            "590/800 loss:0.056 acc:0.901\n",
            "600/800 loss:0.063 acc:0.884\n",
            "610/800 loss:0.057 acc:0.897\n",
            "620/800 loss:0.050 acc:0.914\n",
            "630/800 loss:0.057 acc:0.895\n",
            "640/800 loss:0.067 acc:0.873\n",
            "650/800 loss:0.053 acc:0.903\n",
            "660/800 loss:0.058 acc:0.895\n",
            "670/800 loss:0.062 acc:0.884\n",
            "680/800 loss:0.068 acc:0.871\n",
            "690/800 loss:0.056 acc:0.897\n",
            "700/800 loss:0.054 acc:0.903\n",
            "710/800 loss:0.053 acc:0.906\n",
            "720/800 loss:0.057 acc:0.898\n",
            "730/800 loss:0.060 acc:0.889\n",
            "740/800 loss:0.056 acc:0.896\n",
            "750/800 loss:0.055 acc:0.901\n",
            "760/800 loss:0.044 acc:0.925\n",
            "770/800 loss:0.052 acc:0.908\n",
            "780/800 loss:0.067 acc:0.875\n",
            "790/800 loss:0.042 acc:0.928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efLgO7G1XXCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}